\documentclass[a4paper,11pt]{article}
\usepackage[margin=3cm]{geometry}
\usepackage{hyperref}
\usepackage{enumerate}
\newcommand{\code}[1]{\texttt{#1}}
% !Rnw weave = knitr
\author{P151}
\title{MSc Statistical Programming 2023 Assessed Practical Assignment}

\begin{document}


\maketitle

\subsection{British House Prices}
<<setup, echo = F>>=

# Define needed packages
new_packages <- c("knitr", "readr", "dplyr", "lubridate", "tidyr", "ggplot2", "ggthemes", "xtable", "testthat", "microbenchmark")

# Install new packages not yet installed
installed_new_packages <- new_packages %in% rownames(installed.packages())
if (any(installed_new_packages == FALSE)) {
  install.packages(new_packages[!installed_new_packages])
}

# Load new packages, suppressing startup messages
invisible(lapply(new_packages, function(pkg) {
  suppressPackageStartupMessages(library(pkg, character.only = TRUE))
}))

# use ggthemes so that renv doesn't complain about it
foo <- capture.output(ggthemes::tableau_color_pal())

# Load first data set
houseprices_raw <- suppressMessages(read_csv("Average-prices-2023-07.csv"))
# Load second data set
inflation_raw <- suppressMessages(read_csv("series-181023_cumulative.csv"))

@

Figure \ref{fig1} below displays the evolution of House Prices in England over time.
\begin{figure}[h!]
\centering
\caption{Average House Price in England Over Time}
<<Plot mean House Price in England, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=

# Filter the data for the England region
england_data <- houseprices_raw %>% 
  filter(Region_Name == "England")

# Plot in thousands of pounds
ggplot(england_data, aes(x = Date, y = Average_Price)) +
  geom_line(color = tableau_color_pal()(1)) + 
  scale_y_continuous(labels = scales::comma_format(scale = 1/1000, suffix = "K")) + 
  theme_minimal() +
  labs(
    x = "Date",
    y = "Average Price (in Thousands of £)"
  )
@
\label{fig1}
\end{figure} 

Figure \ref{fig2} below additionally displays the evolution of House Prices in the Oxford Regions as well as England as a whole over time.
\begin{figure}[h!]
\centering
\caption{Comparison of Average House Prices between England and Oxford Regions}
<<Plot for Oxford Houses, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=
# Filter data for Oxford regions
oxford_data <- houseprices_raw %>% 
  filter(grepl("Oxford", Region_Name))

# Merge with England data to get common dates
common_data <- merge(england_data, oxford_data, by = "Date")

# Calculate average price for Oxford regions
oxford_avg <- common_data %>% 
  group_by(Date) %>% 
  summarize(Average_Price_Oxford = mean(Average_Price.y))

# Merge back with England data
final_data <- merge(england_data, oxford_avg, by = "Date")

# Adjusted Plot
ggplot(final_data) +
  geom_line(aes(x = Date, y = Average_Price, color = "England")) +
  geom_line(aes(x = Date, y = Average_Price_Oxford, color = "Oxford Regions")) +
  scale_color_manual(values = tableau_color_pal()(2)) +
  scale_y_continuous(labels = scales::comma_format(scale = 1/1000, suffix = "K")) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(
    x = "Date",
    y = "Average Price (in Thousands of £)",
    color = "Region"
  )

@
\label{fig2}
\end{figure}

Table \ref{tab1} below shows that of the ten regions with the highest median of the ratio $\frac{regional\; average\; house\; price}{average\; house\; price\; in\; England}$. Perhaps unsurprisingly, we can see that the ten most expensive regions by this metric are geographically concentrated in London and its suburbs, and that no Oxford Regions are included.
<<Compare England and Oxford House Prices, results='asis', echo=FALSE>>=
england_regions <- houseprices_raw %>%
  filter(substring(Area_Code, 1, 1) == "E" & Region_Name != "England") %>%
  mutate(Month = floor_date(Date, "month"))

## Calculate median ratios
# First, summarize the England data
england_avg <- england_data %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Month) %>%
  summarize(England_Avg_Price = mean(Average_Price), .groups = 'drop')

# join and calculate ratios
median_ratios <- england_regions %>%
  left_join(england_avg, by = "Month") %>%
  mutate(Ratio = Average_Price / England_Avg_Price) %>%
  group_by(Region_Name) %>%
  summarize(Median_Ratio = median(Ratio, na.rm = TRUE), .groups = 'drop')

# Select top 10 regions
top_regions <- median_ratios %>%
  arrange(desc(Median_Ratio)) %>%
  slice(1:10)

# Calculate initial and final prices, and percentage increase
price_data <- england_regions %>%
  filter(Region_Name %in% top_regions$Region_Name) %>%
  group_by(Region_Name) %>%
  summarize(Initial_Price = first(Average_Price),
            Final_Price = last(Average_Price),
            Percentage_Increase = (Final_Price - Initial_Price) / Initial_Price * 100,
            .groups = 'drop')

# Extract unique Oxford region names
oxford_regions <- unique(oxford_data$Region_Name)

# Create the table
final_table <- left_join(top_regions, price_data, by = "Region_Name") %>%
  mutate(Is_Oxford_Region = Region_Name %in% oxford_regions) %>%
  setNames(c("Region Name", "Median Ratio", "Initial Price",
                    "Final Price", "% Increase", "Oxford?"))


print(xtable(final_table, digits = 2, align = c("l", "l", rep("c", 5)),
             caption = "Ten Highest Median Ratios of Average House Prices",
             label = "tab1"),
      caption.placement = "top",
      size="footnotesize")
@

Figure \ref{fig3} below compares the month-on-month percentage increase in House Prices in England to monthly inflation, defined as the percentage increase in the monthly Consumer Price Index over the period in which data for both is available. We can see that like in most countries, the increase in the average price of a house has drastically outpaced the general cost-of-living increase since the year 2000.
\begin{figure}[h!]
\centering
\caption{Percentage Increase in House Prices compared to Inflation Rate}
<<Inflation plot, echo = F,  fig = T,fig.width=10, fig.height=6, out.width='\\textwidth'>>=
# Extracting the monthly inflation data starting from the 186th row
monthly_inflation <- inflation_raw %>%
  slice(-1:-185) %>%
  mutate(Date = parse_date(Title, format = "%Y %b"),
         Inflation = as.numeric(`CPIH INDEX 00: ALL ITEMS 2015=100`)) %>%
  select(Date, Inflation)

# Ensure England Data has date column
england_data <- england_data %>%
  mutate(Date = as.Date(Date))

# Merge in inflation data
merged_data <- left_join(england_data, monthly_inflation, by = "Date")

# Remove rows with NA in either Average_Price or Inflation
merged_data <- merged_data %>%
  filter(!is.na(Average_Price) & !is.na(Inflation))

# Calculate the percentage increase from the first available data point
merged_data <- merged_data %>%
  mutate(House_Price_Increase = (Average_Price / first(Average_Price) - 1) * 100,
         Inflation_Increase = (Inflation / first(Inflation) - 1) * 100)


# Plot percentage increases with 2 y-axes
ggplot(merged_data, aes(x = Date)) +
  geom_line(aes(y = House_Price_Increase, colour = "House Prices in England"), linewidth = 0.5) +
  geom_line(aes(y = Inflation_Increase, colour = "Inflation Rate"), linewidth = 0.5, linetype = "dashed") +
  scale_colour_manual(values = tableau_color_pal()(2)) +
  theme_minimal() +
  labs(x = "Date", y = "House Price Increase (%)", colour = "Metric") +
  scale_y_continuous(
    name = "Month-to-Month Change in %", #House Price Increase (%)
    labels = scales::percent_format(scale = 1) #,  sec.axis = sec_axis(~ ., name = "Inflation Rate (%)", labels = scales::percent_format(scale = 1))
  ) +
  theme(legend.position = "bottom")

@
\label{fig3}
\end{figure}

\newpage
\section{Chromosome Painting}
\subsection{Implementation of Forward Algorithm}
<<forward algorithm>>=
# Function to calculate emission probability (eq. 3)
emission_probability <- function(observed, reference, error = 0.1) {
  return ((1 - error)^(observed == reference) * error^(observed != reference))
}

# matrices alpha and beta , both with K rows and T columns
forward <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)
  
  # Initialize alpha matrix
  alpha <- matrix(0, nrow = K, ncol = T)
  
  # Compute initial and emission probabilities
  pi <- 1 / K  # (eq. 1)
  for (k in 1:K) { # (eq. 4)
    alpha[k, 1] <- pi * emission_probability(hap[1], haps[k, 1], error)
  }
  
  # Induction step to compute (eq. 5)
  for (t in 2:T) {
    for (k in 1:K) {
      transition_sum <- 0
      for (i in 1:K) {
  A_ik <- ifelse(i == k, (1 - 0.999) / K + 0.999, (1 - 0.999) / K) # (eq. 2)
  transition_sum <- transition_sum + alpha[i, t - 1] * A_ik
  }
      b_kt <- emission_probability(hap[t], haps[k, t], error)
      alpha[k, t] <- transition_sum * b_kt
    }
  }
  
  return(alpha)
}

@

\subsection{Unit Test for Forward Algorithm Implementation}
<<unit test for forward algorithm>>=
test_that("alpha matrix has expected form when haps and hap always match", {
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)
  
  # Create haps and hap such that they always match (both all 0)
  haps <- matrix(0, nrow = K, ncol = T)
  hap <- rep(0, T)
  
  # Run the forward function
  alpha <- forward(haps, hap, error = e)
  
  # Check first column
  expected_first_column <- rep((1 - e) / K, K)
  expect_equal(alpha[, 1], expected_first_column)
  
  # Check all other columns
  for (t in 2:T) {
    expect_equal(alpha[, t], alpha[, t - 1] * (1 - e), tolerance = 1e-5)
  }
})
@

\subsection{Implementation of Backward Algorithm}
<<backward algorithm>>=
backward <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)
  
  # Initialize beta matrix (eq. 6)
  beta <- matrix(0, nrow = K, ncol = T)  
  beta[, T] <- 1  # Set last column to 1
  
  # Induction step (eq. 7)
  for (t in (T-1):1) {
      for (k in 1:K) {
        sum_transition <- 0
        for (i in 1:K) { # (eq. 2)
          A_ki <- ifelse(k == i, (1 - 0.999) / K + 0.999, (1 - 0.999) / K)  
          b_i_t_plus_1 <- emission_probability(hap[t+1], haps[i, t+1], error)
          sum_transition <- sum_transition + 
              A_ki * b_i_t_plus_1 * beta[i, t+1]
        }
        beta[k, t] <- sum_transition
      }
    }
  
  return(beta)
}

@
\newpage
\subsection{Implementation of Gamma Function}
<<gamma function>>=
gamma <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)

  # Compute alpha and beta matrices
  alpha <- forward(haps, hap, error)
  beta <- backward(haps, hap, error)

  # Compute normalization factor (denominator)
  norm_factor <- sum(alpha[, T])

  # Initialize gamma matrix
  gamma_matrix <- matrix(0, nrow = K, ncol = T)

  # Update gamma values (eq. 8)
  for (t in 1:T) {
    for (k in 1:K) {
      gamma_matrix[k, t] <- (alpha[k, t] * beta[k, t]) / norm_factor
    }

  return(gamma_matrix)
  }
}

@

\subsection{Unit Test for Gamma Function Implementation}
<<unit test for gamma function>>=
test_that("column sums of gamma matrix sum to 1", {
  set.seed(42)  # For reproducibility
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)

  # Create random haps and hap with 0 or 1 entries
  haps <- matrix(sample(0:1, K * T, replace = T), nrow = K, ncol = T)
  hap <- sample(0:1, T, replace = T)

  # Run the gamma function
  gamma_matrix <- gamma(haps, hap, error = e)

   # Check total sum
  total_sum <- sum(gamma_matrix)
  expect_equal(total_sum, 1, tolerance = 1e-5)
})
@

\subsection{Computational Complexity of Forward and Backward Algorithms}
\begin{enumerate}
\item The forward algorithm has a time complexity of $\mathcal{O}(K^2 \cdot T)$ as for each time step $t$, it iterates over $K$ states, and within each state again iterates over $K$ states to compute the transition probabilities.
\item The backward algorithm has an identical time complexity of $\mathcal{O}(K^2 \cdot T)$ as it performs the same iterations, just in a different oder.
\end{enumerate}
\end{document}

