\documentclass[a4paper,11pt]{article}
\usepackage[margin=3cm]{geometry}
\usepackage{hyperref}
\usepackage{enumerate}
\newcommand{\code}[1]{\texttt{#1}}
% !Rnw weave = knitr
\author{P151}
\title{MSc Statistical Programming 2023 Assessed Practical Assignment}

\begin{document}


\maketitle

\subsection{British House Prices}
<<setup, echo = F>>=

# Define needed packages
new_packages <- c("knitr", "readr", "dplyr", "lubridate", "tidyr", "ggplot2", "ggthemes", "xtable", "testthat", "microbenchmark", "parallel")

# Install new packages not yet installed
installed_new_packages <- new_packages %in% rownames(installed.packages())
if (any(installed_new_packages == FALSE)) {
  install.packages(new_packages[!installed_new_packages])
}

# Load new packages, suppressing startup messages
invisible(lapply(new_packages, function(pkg) {
  suppressPackageStartupMessages(library(pkg, character.only = TRUE))
}))

# use ggthemes so that renv doesn't complain about it
foo <- capture.output(ggthemes::tableau_color_pal())

# Load first data set
houseprices_raw <- suppressMessages(read_csv("Average-prices-2023-07.csv"))
# Load second data set
inflation_raw <- suppressMessages(read_csv("series-181023_cumulative.csv"))

@

Figure \ref{fig1} below displays the evolution of House Prices in England over time.
\begin{figure}[h!]
\centering
\caption{Average House Price in England Over Time}
<<Plot mean House Price in England, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=

# Filter the data for the England region
england_data <- houseprices_raw %>% 
  filter(Region_Name == "England")

# Plot in thousands of pounds
ggplot(england_data, aes(x = Date, y = Average_Price)) +
  geom_line(color = tableau_color_pal()(1)) + 
  scale_y_continuous(labels = scales::comma_format(scale = 1/1000, suffix = "K")) + 
  theme_minimal() +
  labs(
    x = "Date",
    y = "Average Price (in Thousands of £)"
  )
@
\label{fig1}
\end{figure} 

Figure \ref{fig2} below additionally displays the evolution of House Prices in the Oxford Regions as well as England as a whole over time.
\begin{figure}[h!]
\centering
\caption{Comparison of Average House Prices between England and Oxford Regions}
<<Plot for Oxford Houses, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=
# Filter data for Oxford regions
oxford_data <- houseprices_raw %>% 
  filter(grepl("Oxford", Region_Name))

# Merge with England data to get common dates
common_data <- merge(england_data, oxford_data, by = "Date")

# Calculate average price for Oxford regions
oxford_avg <- common_data %>% 
  group_by(Date) %>% 
  summarize(Average_Price_Oxford = mean(Average_Price.y))

# Merge back with England data
final_data <- merge(england_data, oxford_avg, by = "Date")

# Adjusted Plot
ggplot(final_data) +
  geom_line(aes(x = Date, y = Average_Price, color = "England")) +
  geom_line(aes(x = Date, y = Average_Price_Oxford, color = "Oxford Regions")) +
  scale_color_manual(values = tableau_color_pal()(2)) +
  scale_y_continuous(labels = scales::comma_format(scale = 1/1000, suffix = "K")) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(
    x = "Date",
    y = "Average Price (in Thousands of £)",
    color = "Region"
  )

@
\label{fig2}
\end{figure}

Table \ref{tab1} below shows that of the ten regions with the highest median of the ratio $\frac{regional\; average\; house\; price}{average\; house\; price\; in\; England}$. Perhaps unsurprisingly, we can see that the ten most expensive regions by this metric are geographically concentrated in London and its suburbs, and that no Oxford Regions are included.
<<Compare England and Oxford House Prices, results='asis', echo=FALSE>>=
england_regions <- houseprices_raw %>%
  filter(substring(Area_Code, 1, 1) == "E" & Region_Name != "England") %>%
  mutate(Month = floor_date(Date, "month"))

## Calculate median ratios
# First, summarize the England data
england_avg <- england_data %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Month) %>%
  summarize(England_Avg_Price = mean(Average_Price), .groups = 'drop')

# join and calculate ratios
median_ratios <- england_regions %>%
  left_join(england_avg, by = "Month") %>%
  mutate(Ratio = Average_Price / England_Avg_Price) %>%
  group_by(Region_Name) %>%
  summarize(Median_Ratio = median(Ratio, na.rm = TRUE), .groups = 'drop')

# Select top 10 regions
top_regions <- median_ratios %>%
  arrange(desc(Median_Ratio)) %>%
  slice(1:10)

# Calculate initial and final prices, and percentage increase
price_data <- england_regions %>%
  filter(Region_Name %in% top_regions$Region_Name) %>%
  group_by(Region_Name) %>%
  summarize(Initial_Price = first(Average_Price),
            Final_Price = last(Average_Price),
            Percentage_Increase = (Final_Price - Initial_Price) / Initial_Price * 100,
            .groups = 'drop')

# Extract unique Oxford region names
oxford_regions <- unique(oxford_data$Region_Name)

# Create the table
final_table <- left_join(top_regions, price_data, by = "Region_Name") %>%
  mutate(Is_Oxford_Region = Region_Name %in% oxford_regions) %>%
  setNames(c("Region Name", "Median Ratio", "Initial Price",
                    "Final Price", "% Increase", "Oxford?"))


print(xtable(final_table, digits = 2, align = c("l", "l", rep("c", 5)),
             caption = "Ten Highest Median Ratios of Average House Prices",
             label = "tab1"),
      caption.placement = "top",
      size="footnotesize")
@

Figure \ref{fig3} below compares the month-on-month percentage increase in House Prices in England to monthly inflation, defined as the percentage increase in the monthly Consumer Price Index over the period in which data for both is available. We can see that like in most countries, the increase in the average price of a house has drastically outpaced the general cost-of-living increase since the year 2000.
\begin{figure}[h!]
\centering
\caption{Percentage Increase in House Prices compared to Inflation Rate}
<<Inflation plot, echo = F,  fig = T,fig.width=10, fig.height=6, out.width='\\textwidth'>>=
# Extracting the monthly inflation data starting from the 186th row
monthly_inflation <- inflation_raw %>%
  slice(-1:-185) %>%
  mutate(Date = parse_date(Title, format = "%Y %b"),
         Inflation = as.numeric(`CPIH INDEX 00: ALL ITEMS 2015=100`)) %>%
  select(Date, Inflation)

# Ensure England Data has date column
england_data <- england_data %>%
  mutate(Date = as.Date(Date))

# Merge in inflation data
merged_data <- left_join(england_data, monthly_inflation, by = "Date")

# Remove rows with NA in either Average_Price or Inflation
merged_data <- merged_data %>%
  filter(!is.na(Average_Price) & !is.na(Inflation))

# Calculate the percentage increase from the first available data point
merged_data <- merged_data %>%
  mutate(House_Price_Increase = (Average_Price / first(Average_Price) - 1) * 100,
         Inflation_Increase = (Inflation / first(Inflation) - 1) * 100)


# Plot percentage increases with 2 y-axes
ggplot(merged_data, aes(x = Date)) +
  geom_line(aes(y = House_Price_Increase, colour = "House Prices in England"), linewidth = 0.5) +
  geom_line(aes(y = Inflation_Increase, colour = "Inflation Rate"), linewidth = 0.5, linetype = "dashed") +
  scale_colour_manual(values = tableau_color_pal()(2)) +
  theme_minimal() +
  labs(x = "Date", y = "House Price Increase (%)", colour = "Metric") +
  scale_y_continuous(
    name = "Month-to-Month Change in %", #House Price Increase (%)
    labels = scales::percent_format(scale = 1) #,  sec.axis = sec_axis(~ ., name = "Inflation Rate (%)", labels = scales::percent_format(scale = 1))
  ) +
  theme(legend.position = "bottom")

@
\label{fig3}
\end{figure}

\newpage
\section{Chromosome Painting}
\subsection{Implementation of \texttt{forward} Algorithm}
<<forward algorithm>>=
# Function to calculate emission probability (eq. 3)
emission_probability <- function(observed, reference, error = 0.1) {
  return ((1 - error)^(observed == reference) * error^(observed != reference))
}

# matrices alpha and beta , both with K rows and T columns
forward <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)
  
  # Initialize alpha matrix
  alpha <- matrix(0, nrow = K, ncol = T)
  
  # Compute initial and emission probabilities
  pi <- 1 / K  # (eq. 1)
  for (k in 1:K) { # (eq. 4)
    alpha[k, 1] <- pi * emission_probability(hap[1], haps[k, 1], error)
  }
  
  # Induction step to compute (eq. 5)
  for (t in 2:T) {
    for (k in 1:K) {
      transition_sum <- 0
      for (i in 1:K) {
  A_ik <- ifelse(i == k, (1 - 0.999) / K + 0.999, (1 - 0.999) / K) # (eq. 2)
  transition_sum <- transition_sum + alpha[i, t - 1] * A_ik
  }
      b_kt <- emission_probability(hap[t], haps[k, t], error)
      alpha[k, t] <- transition_sum * b_kt
    }
  }
  
  return(alpha)
}

@

\subsection{Unit Test for \texttt{forward} Algorithm Implementation}
<<unit test for forward algorithm>>=
test_that("alpha matrix has expected form when haps and hap always match", {
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)
  
  # Create haps and hap such that they always match (both all 0)
  haps <- matrix(0, nrow = K, ncol = T)
  hap <- rep(0, T)
  
  # Run the forward function
  alpha <- forward(haps, hap, error = e)
  
  # Check first column
  expected_first_column <- rep((1 - e) / K, K)
  expect_equal(alpha[, 1], expected_first_column)
  
  # Check all other columns
  for (t in 2:T) {
    expect_equal(alpha[, t], alpha[, t - 1] * (1 - e), tolerance = 1e-5)
  }
})
@

\subsection{Implementation of \texttt{backward} Algorithm}
<<backward algorithm>>=
backward <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)
  
  # Initialize beta matrix (eq. 6)
  beta <- matrix(0, nrow = K, ncol = T)  
  beta[, T] <- 1  # Set last column to 1
  
  # Induction step (eq. 7)
  for (t in (T-1):1) {
      for (k in 1:K) {
        sum_transition <- 0
        for (i in 1:K) { # (eq. 2)
          A_ki <- ifelse(k == i, (1 - 0.999) / K + 0.999, (1 - 0.999) / K)  
          b_i_t_plus_1 <- emission_probability(hap[t+1], haps[i, t+1], error)
          sum_transition <- sum_transition + 
              A_ki * b_i_t_plus_1 * beta[i, t+1]
        }
        beta[k, t] <- sum_transition
      }
    }
  
  return(beta)
}

@
\newpage
\subsection{Implementation of \texttt{gamma} Function}
<<gamma function>>=
gamma <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)

  # Compute alpha and beta matrices
  alpha <- forward(haps, hap, error)
  beta <- backward(haps, hap, error)

  # Compute normalization factor (denominator)
  norm_factor <- sum(alpha[, T])

  # Initialize gamma matrix
  gamma_matrix <- matrix(0, nrow = K, ncol = T)

  # Update gamma values (eq. 8)
  for (t in 1:T) {
    for (k in 1:K) {
      gamma_matrix[k, t] <- (alpha[k, t] * beta[k, t]) / norm_factor
    }
  }
  return(gamma_matrix)
}

@

\subsection{Unit Test for \texttt{gamma} Function Implementation}
<<unit test for gamma function>>=
# test_that("column sums of gamma matrix sum to 1", {
#   set.seed(42)  # For reproducibility
#   K <- 10  # Number of rows in haps
#   T <- 15  # Number of columns in haps = length of hap
#   e <- 0.1  # Error rate (= default value)
# 
#   # Create random haps and hap with 0 or 1 entries
#   haps <- matrix(sample(0:1, K * T, replace = T), nrow = K, ncol = T)
#   hap <- sample(0:1, T, replace = T)
# 
#   # Run the gamma function
#   gamma_matrix <- gamma(haps, hap, error = e)
# 
#    # Check total sum
#   total_sum <- sum(gamma_matrix)
#   expect_equal(total_sum, 1, tolerance = 1e-5)
# })
test_that("column sums of gamma matrix all equal 1", {
  set.seed(42)  # For reproducibility
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)

  # Create random haps and hap with 0 or 1 entries
  haps <- matrix(sample(0:1, K * T, replace = TRUE), nrow = K, ncol = T)
  hap <- sample(0:1, T, replace = TRUE)

  # Run the gamma function
  gamma_matrix <- gamma(haps, hap, error = e)

  # Check that each column sum is close to 1
  for (t in 1:T) {
    expect_equal(sum(gamma_matrix[, t]), 1, tolerance = 1e-5)
  }
})

@

\subsection{Computational Complexity of \texttt{forward} and \texttt{backward} Algorithms}
\begin{enumerate}
\item The \texttt{forward} algorithm has a time complexity of $\mathcal{O}(K^2 \cdot T)$ as for each time step $t$, it iterates over $K$ states, and within each state again iterates over $K$ states to compute the transition probabilities.
\item The \texttt{backward} algorithm has an identical time complexity of $\mathcal{O}(K^2 \cdot T)$ as it performs the same iterations, just in a different oder.
\end{enumerate}

Figures \ref{fig4} and \ref{fig5} below show benchmark results for both the forward and backward algorithms, executed $10$ times each for all $K \times T$ with $K, L ={5, \ldots, 20}$. The fitted lines for the median execution time for each value of $K$ and $T$, respectively, look polynomial in $K$ and linear in $T$. 
<<Benchmarking and Plotting Functions, echo = F>>=
# Standardized Benchmarking Function
run_benchmark <- function(algo_func) {
  sizes <- expand.grid(K = 5:20, T = 5:20)
  bench_results <- data.frame(K = integer(), T = integer(), time = numeric())

  for (i in 1:nrow(sizes)) {
    size <- sizes[i,]
    K <- size$K
    T <- size$T
    haps <- matrix(sample(0:1, K * T, replace = TRUE), nrow = K)
    hap <- sample(0:1, T, replace = TRUE)
    
    # Using mclapply to run in parallel
    benchmark <- mclapply(1:10, function(i) {
        system.time(algo_func(haps, hap, error = 0.1))[3]
    }, mc.cores = detectCores() - 1)
    
    # Collecting results
    mean_time <- mean(sapply(benchmark, `[[`, 1))
    bench_results <- rbind(bench_results, data.frame(K = K, T = T, 
                                                     time = mean_time))
  }

  # Transform to long format
  bench_results_long <- bench_results %>%
    gather(key = "variable", value = "value", K, T)
  
  return(bench_results_long)
}

# Plotting function for benchmark results
plot_benchmark <- function(bench_results){
  colors <- tableau_color_pal()(4) # get plot colors
cap <- "Median execution time required for varying values of K and T. Each point represents the median execution time across all 10 simulations for a given K or T. \nThe red and turquoise lines are smoothed fits on all data points indicating the trend of time complexity, with fitting quadratic in K and linear in T"

# plot
benchplot <- ggplot(bench_results, aes(x = value, y = time)) +
  stat_summary(
    fun = median, geom = "point", 
    aes(color = variable), size = 1.5, 
    show.legend = F 
  ) +
  geom_smooth(
    data = bench_results %>% filter(variable == "K"), 
    aes(x = value, y = time), 
    method = "lm", formula = y ~ poly(x, 2, raw = T), 
    color = colors[3], se = T
  ) +
  geom_smooth(
    data = bench_results %>% filter(variable == "T"), 
    aes(x = value, y = time), 
    method = "lm", formula = y ~ x, 
    color = colors[4], se = T
  ) +
  facet_wrap(~variable, scales = 'free_x') +
  labs(x = "Value of K/T", y = "Time (seconds)",
       caption = cap) +
  theme_minimal() +
  scale_color_manual(values = colors[1:2])

  return(benchplot)
}
@

\begin{figure}[h!]
\centering
\caption{Benchmark Results for \texttt{forward} Algorithm}
<<Benchmark Plot for forward, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=
plot_benchmark(run_benchmark(forward))
@
\label{fig4}
\end{figure}
\begin{figure}[h!]
\centering
\caption{Benchmark Results for \texttt{backward} Algorithm}
<<Benchmark Plot for backward, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=
# Benchmark function
plot_benchmark(run_benchmark(backward))
@
\label{fig5}
\end{figure}
\newpage

\subsection{Implementation of \texttt{forward2} Algorithm}
<<forward2 implementation>>=
forward2 <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)
  alpha <- matrix(0, nrow = K, ncol = T)
  pi <- 1 / K

  for (k in 1:K) {
    alpha[k, 1] <- pi * emission_probability(hap[1], haps[k, 1], error)
  }

  for (t in 2:T) {
    phi <- sum(alpha[, t - 1]) * (1 - 0.999) / K
    for (k in 1:K) {
      A_ik <- ifelse(k == k, (1 - 0.999) / K + 0.999, (1 - 0.999) / K)
      b_kt <- emission_probability(hap[t], haps[k, t], error)
      alpha[k, t] <- (phi + 0.999 * alpha[k, t - 1]) * b_kt
    }
  }

  return(alpha)
}
@

<<unit test for forward2 >>=
test_that("forward and forward2 produce the same outputs", {
  set.seed(42)  # For reproducibility
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)

  # Generate example data
  haps <- matrix(sample(0:1, K * T, replace = TRUE), nrow = K)
  hap <- sample(0:1, T, replace = TRUE)

  # Run both functions
  alpha_forward <- forward(haps, hap, e)
  alpha_forward2 <- forward2(haps, hap, e)

  # Check if the outputs are equal
  expect_equal(alpha_forward, alpha_forward2, tolerance = 1e-5)
})
@
The \texttt{forward2} algorithm has a time complexity of $\mathcal{O}(K \cdot T)$ as it computes the initial probabilities ($\mathcal{O}(K)$) and then for each time step $t$, it sums over all $K$ states ($\mathcal{O}(K)$) and computes equation (14) ($\mathcal{O}(1)$). Since the main loop runs for each time step $T$, and within each time step, two $\mathcal{O}(K)$ operations are performed (one for summing alpha and one for the loop over $K$), the overall complexity of the forward2 function is $\mathcal{O}(K \cdot T)$. Figure \ref{fig6} below displays this improved performance.

\begin{figure}[h!]
\centering
\caption{Benchmark Results for \texttt{forward2} Algorithm}
<<Benchmark Plot for forward2, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=
# Benchmark function
plot_benchmark(run_benchmark(forward2))
@
\label{fig6}
\end{figure}

\subsection{Implementation of \texttt{backward2} Algorithm}
<<backward2 algorithm>>=
backward2 <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)

  # Initialize beta matrix (eq. 6)
  beta <- matrix(0, nrow = K, ncol = T)  
  beta[, T] <- 1  # Set last column to 1
  
  # Induction step (eq. 14)
  for (t in (T-1):1) {
    # Calculate the phi term which is constant for all k (eq. 13)
    phi <- sum(beta[, t+1] * sapply(1:K, function(i) emission_probability(hap[t+1], haps[i, t+1], error))) * (1 - 0.999) / K
    
    for (k in 1:K) { # Update beta for each k using the phi term and the specific transition and emission probabilities for k (eq. 14)
      beta[k, t] <- phi + 0.999 * beta[k, t+1] * emission_probability(hap[t+1], haps[k, t+1], error)
    }
  }
  
  return(beta)
}
@

<<unit test for backward2 >>=
test_that("backward and backward2 produce the same outputs", {
  set.seed(42)  # For reproducibility
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)

  # Generate example data
  haps <- matrix(sample(0:1, K * T, replace = TRUE), nrow = K)
  hap <- sample(0:1, T, replace = TRUE)

  # Run both functions
  beta_backward <- backward(haps, hap, e)
  beta_backward2 <- backward2(haps, hap, e)

  # Check if the outputs are equal
  expect_equal(beta_backward, beta_backward2, tolerance = 1e-5)
})
@
The \texttt{backward2} algorithm has a time complexity of $\mathcal{O}(K \cdot T)$ as it computes the initial probabilities ($\mathcal{O}(K)$) and then for each time step $t$, it sums over all $K$ states ($\mathcal{O}(K)$) and computes equation (14) ($\mathcal{O}(1)$). Since the main loop runs for each time step $T$, and within each time step, two $\mathcal{O}(K)$ operations are performed (one for summing alpha and one for the loop over $K$), the overall complexity of the forward2 function is $\mathcal{O}(K \cdot T)$. Figure \ref{fig7} below displays this improved performance.

\begin{figure}[h!]
\centering
\caption{Benchmark Results for \texttt{backward2} Algorithm}
<<Benchmark Plot for backward2, echo = F,  fig = T,fig.width=10, fig.height=4, out.width='\\textwidth'>>=
# Benchmark function
plot_benchmark(run_benchmark(backward2))
@
\label{fig7}
\end{figure}

\subsection{Implementation of \textt{gamma2} Function}
<<gamma2 implementation>>=
gamma2 <- function(haps, hap, error = 0.1) {
  K <- nrow(haps)
  T <- ncol(haps)

  # Compute alpha and beta matrices using forward2 and backward2
  alpha <- forward2(haps, hap, error)
  beta <- backward2(haps, hap, error)

  # Compute normalization factor (denominator)
  norm_factor <- sum(alpha[, T])

  # Initialize gamma matrix
  gamma_matrix <- matrix(0, nrow = K, ncol = T)

  # Update gamma values (eq. 8)
  for (t in 1:T) {
    for (k in 1:K) {
      gamma_matrix[k, t] <- (alpha[k, t] * beta[k, t]) / norm_factor
    }
  }

  return(gamma_matrix)
}
@

<<unit test for gamma2>>=
test_that("gamma and gamma2 produce the same outputs", {
  set.seed(42)  # For reproducibility
  K <- 10  # Number of rows in haps
  T <- 15  # Number of columns in haps = length of hap
  e <- 0.1  # Error rate (= default value)

  # Generate example data
  haps <- matrix(sample(0:1, K * T, replace = TRUE), nrow = K)
  hap <- sample(0:1, T, replace = TRUE)

  # Run both functions
  gamma_matrix <- gamma(haps, hap, e)
  gamma_matrix2 <- gamma2(haps, hap, e)

  # Check if the outputs are equal
  expect_equal(gamma_matrix, gamma_matrix2, tolerance = 1e-5)
})
@
\begin{enumerate}
\item Based on the previous discussion, executing \texttt{forward2} and \texttt{backward2} each costs $\mathcal{O}(K \cdot T)$. Computing the normalization factor (norm_factor) involves summing over one column of the \texttt{alpha} matrix, which is $\mathcal{O}(K)$. The nested loop structure for updating the \texttt{gamma} matrix involves iterating over $T$ and each $K$. Within the inner loop, the operation to calculate each entry is $\mathcal{O}(1)$. Therefore, the complexity of updating the gamma_matrix is $\mathcal{O}(K \cdot T)$. With 3 operations in $\mathcal{O}(K \cdot T)$, the overall time complexity of \texttt{gamma2} is $\mathcal{O}(K \cdot T)$.
\item By the same logic, executing \texttt{forward} and \texttt{backward} each costs $\mathcal{O}(K^2 \cdot T)$, which dominates the other terms that contribute to the time complexity of \texttt{gamma}, which as an overall time complexity of $\mathcal{O}(K^2 \cdot T)$
\end{enumerate}



<<empirical complexity of gamma and gamma2>>=

@



\end{document}

